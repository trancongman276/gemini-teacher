# -*- coding: utf-8 -*-

# Copyright 2023 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from websockets.legacy.client import WebSocketClientProtocol
from websockets_proxy import Proxy, proxy_connect
import asyncio
import base64
import json
import os
import sys
import pyaudio
from rich.console import Console
from rich.markdown import Markdown
from websockets.asyncio.client import connect
from websockets.asyncio.connection import Connection
from elevenlabs import ElevenLabs, play
import numpy as np
import dotenv

dotenv.load_dotenv()

# åŸºç¡€é…ç½®
FORMAT = pyaudio.paInt16
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 16000
CHUNK_SIZE = 512

host = "generativelanguage.googleapis.com"
model = "gemini-2.0-flash-exp"
api_key = os.environ["GOOGLE_API_KEY"]
uri = f"wss://{host}/ws/google.ai.generativelanguage.v1alpha.GenerativeService.BidiGenerateContent?key={api_key}"

# è¯­éŸ³è®¾ç½®
pya = pyaudio.PyAudio()
voice_api_key = os.environ.get("ELEVENLABS_API_KEY")
voice_model = "eleven_flash_v2_5"
voice_voice_id = "nPczCjzI2devNBz1zQrb"

# ä¸»é¢˜å’Œåœºæ™¯å®šä¹‰
THEMES = {
    "business": ["job interview", "business meeting", "presentation", "networking"],
    "travel": ["airport", "hotel", "restaurant", "sightseeing"],
    "daily life": ["shopping", "weather", "hobbies", "family"],
    "social": ["meeting friends", "party", "social media", "dating"],
}

class AudioLoop:
    def __init__(self):
        self.ws: WebSocketClientProtocol | Connection
        self.audio_out_queue = asyncio.Queue()
        self.running_step = 0
        self.paused = False
        self.current_theme = None
        self.current_scenario = None
        self.console = Console()
        self.voice_client = None
        
        # åˆå§‹åŒ–è¯­éŸ³å®¢æˆ·ç«¯
        if voice_api_key:
            self.console.print("å¯åŠ¨è¯­éŸ³æ¨¡å¼", style="green")
            self.voice_client = ElevenLabs(api_key=voice_api_key)
        else:
            self.console.print("è¯­éŸ³æ¨¡å¼å…³é—­ï¼Œæ‰¾ä¸åˆ° ELEVENLABS_API_KEY", style="red")

    def calculate_pronunciation_score(self, audio_data):
        """è®¡ç®—å‘éŸ³å¾—åˆ†"""
        try:
            audio_array = np.frombuffer(audio_data, dtype=np.int16)
            
            # è®¡ç®—éŸ³é¢‘ç‰¹å¾
            energy = np.mean(np.abs(audio_array))
            zero_crossings = np.sum(np.abs(np.diff(np.signbit(audio_array))))
            
            # å½’ä¸€åŒ–å¹¶è®¡ç®—å¾—åˆ†
            energy_score = min(100, energy / 1000)
            rhythm_score = min(100, zero_crossings / 100)
            
            # æœ€ç»ˆå¾—åˆ†
            final_score = int(0.6 * energy_score + 0.4 * rhythm_score)
            return min(100, max(0, final_score))
        except Exception as e:
            self.console.print(f"è¯„åˆ†è®¡ç®—é”™è¯¯: {e}", style="red")
            return 70  # å‡ºé”™æ—¶è¿”å›é»˜è®¤åˆ†æ•°

    async def startup(self):
        """åˆå§‹åŒ–å¯¹è¯"""
        # è®¾ç½®åˆå§‹é…ç½®
        setup_msg = {
            "setup": {
                "model": f"models/{model}",
                "generation_config": {"response_modalities": ["TEXT"]},
            }
        }
        await self.ws.send(json.dumps(setup_msg))
        await self.ws.recv()

        # å‘é€åˆå§‹æç¤º
        initial_msg = {
            "client_content": {
                "turns": [
                    {
                        "role": "user",
                        "parts": [
                            {
                                "text": """ä½ æ˜¯ä¸€åä¸“ä¸šçš„è‹±è¯­å£è¯­æŒ‡å¯¼è€å¸ˆã€‚è¯·ç”¨ä¸­è‹±æ–‡åŒè¯­è¿›è¡Œå›å¤ï¼Œè‹±æ–‡åœ¨å‰ä¸­æ–‡åœ¨åï¼Œç”¨ --- åˆ†éš”ã€‚
                                
Your responsibilities are:
1. Help users correct grammar and pronunciation
2. Give pronunciation scores and detailed feedback
3. Understand and respond to control commands:
   - Pause when user says "Can I have a break"
   - Continue when user says "OK let's continue"
4. Provide practice sentences based on chosen themes and scenarios

ä½ çš„èŒè´£æ˜¯ï¼š
1. å¸®åŠ©ç”¨æˆ·çº æ­£è¯­æ³•å’Œå‘éŸ³
2. ç»™å‡ºå‘éŸ³è¯„åˆ†å’Œè¯¦ç»†åé¦ˆ
3. ç†è§£å¹¶å“åº”ç”¨æˆ·çš„æ§åˆ¶æŒ‡ä»¤ï¼š
   - å½“ç”¨æˆ·è¯´"Can I have a break"æ—¶æš‚åœ
   - å½“ç”¨æˆ·è¯´"OK let's continue"æ—¶ç»§ç»­
4. åŸºäºé€‰æ‹©çš„ä¸»é¢˜å’Œåœºæ™¯æä¾›ç»ƒä¹ å¥å­

First, ask which theme they want to practice (business, travel, daily life, social) in English.

æ¯æ¬¡ç”¨æˆ·è¯´å®Œä¸€ä¸ªå¥å­åï¼Œä½ éœ€è¦ï¼š
1. è¯†åˆ«ç”¨æˆ·è¯´çš„å†…å®¹ï¼ˆè‹±æ–‡ï¼‰
2. ç»™å‡ºå‘éŸ³è¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰
3. è¯¦ç»†è¯´æ˜å‘éŸ³å’Œè¯­æ³•ä¸­çš„é—®é¢˜ï¼ˆä¸­è‹±æ–‡å¯¹ç…§ï¼‰
4. æä¾›æ”¹è¿›å»ºè®®ï¼ˆä¸­è‹±æ–‡å¯¹ç…§ï¼‰
5. æä¾›ä¸‹ä¸€ä¸ªç›¸å…³åœºæ™¯çš„ç»ƒä¹ å¥å­ï¼ˆä¸­è‹±æ–‡å¯¹ç…§ï¼‰

è¯·å§‹ç»ˆä¿æŒä»¥ä¸‹æ ¼å¼ï¼š
[English content]
---
[ä¸­æ–‡å†…å®¹]

å¦‚æœæ˜ç™½äº†è¯·ç”¨ä¸­è‹±æ–‡å›ç­”OK"""
                            }
                        ],
                    }
                ],
                "turn_complete": True,
            }
        }
        await self.ws.send(json.dumps(initial_msg))
        
        # ç­‰å¾…AIå›å¤OK
        current_response = []
        async for raw_response in self.ws:
            response = json.loads(raw_response)
            try:
                if "serverContent" in response:
                    parts = response["serverContent"].get("modelTurn", {}).get("parts", [])
                    for part in parts:
                        if "text" in part:
                            current_response.append(part["text"])
            except Exception:
                pass

            try:
                turn_complete = response["serverContent"]["turnComplete"]
                if turn_complete:
                    if "".join(current_response).startswith("OK"):
                        self.console.print("åˆå§‹åŒ–å®Œæˆ âœ…", style="green")
                        return
            except KeyError:
                pass

    async def listen_audio(self):
        """ç›‘å¬éŸ³é¢‘è¾“å…¥"""
        mic_info = pya.get_default_input_device_info()
        stream = pya.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )

        self.console.print("ğŸ¤ è¯·è¯´è‹±è¯­", style="yellow")

        while True:
            if self.paused:
                await asyncio.sleep(0.1)
                continue

            data = await asyncio.to_thread(stream.read, CHUNK_SIZE)
            if self.running_step > 1:
                continue

            # éŸ³é‡æ£€æµ‹
            audio_data = []
            for i in range(0, len(data), 2):
                sample = int.from_bytes(data[i:i+2], byteorder="little", signed=True)
                audio_data.append(abs(sample))
            volume = sum(audio_data) / len(audio_data)

            if volume > 200:
                if self.running_step == 0:
                    self.console.print("ğŸ¤ :", style="yellow", end="")
                    self.running_step += 1
                self.console.print("*", style="green", end="")
            await self.audio_out_queue.put(data)

    async def send_audio(self):
        """å‘é€éŸ³é¢‘æ•°æ®"""
        while True:
            if self.paused:
                await asyncio.sleep(0.1)
                continue

            chunk = await self.audio_out_queue.get()
            msg = {
                "realtime_input": {
                    "media_chunks": [
                        {
                            "data": base64.b64encode(chunk).decode(),
                            "mime_type": "audio/pcm",
                        }
                    ]
                }
            }
            await self.ws.send(json.dumps(msg))

    async def receive_audio(self):
        """æ¥æ”¶å’Œå¤„ç†å“åº”"""
        current_response = []
        async for raw_response in self.ws:
            if self.running_step == 1:
                self.console.print("\nâ™»ï¸ å¤„ç†ä¸­ï¼š", end="")
                self.running_step += 1

            response = json.loads(raw_response)
            try:
                if "serverContent" in response:
                    parts = response["serverContent"].get("modelTurn", {}).get("parts", [])
                    for part in parts:
                        if "text" in part:
                            current_response.append(part["text"])
                            self.console.print("-", style="blue", end="")
            except Exception:
                pass

            try:
                turn_complete = response["serverContent"]["turnComplete"]
                if turn_complete and current_response:
                    text = "".join(current_response)
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ§åˆ¶å‘½ä»¤
                    if "can i have a break" in text.lower():
                        self.paused = True
                        self.console.print("\nâ¸ï¸ ä¼šè¯å·²æš‚åœã€‚è¯´ 'OK let's continue' ç»§ç»­", style="yellow")
                    elif "ok let's continue" in text.lower() and self.paused:
                        self.paused = False
                        self.console.print("\nâ–¶ï¸ ä¼šè¯ç»§ç»­", style="green")
                    
                    # æ˜¾ç¤ºå“åº”
                    self.console.print("\nğŸ¤– =============================================", style="yellow")
                    self.console.print(Markdown(text))
                    
                    # æ’­æ”¾è¯­éŸ³
                    if self.voice_client and not self.paused:
                        try:
                            def play_audio():
                                # åˆ†å‰²ä¸­è‹±æ–‡å†…å®¹
                                parts = text.split('---')
                                if len(parts) > 0:
                                    # åªæ’­æ”¾è‹±æ–‡éƒ¨åˆ†ï¼ˆç¬¬ä¸€éƒ¨åˆ†ï¼‰
                                    english_text = parts[0].strip()
                                    voice_stream = self.voice_client.text_to_speech.convert_as_stream(
                                        voice_id=voice_voice_id,
                                        text=english_text,
                                        model_id=voice_model,
                                    )
                                    play(voice_stream)

                            self.console.print("ğŸ™ å£°éŸ³æ’­æ”¾ä¸­........", style="yellow")
                            await asyncio.to_thread(play_audio)
                            self.console.print("ğŸ™ æ’­æ”¾å®Œæ¯•", style="green")
                        except Exception as e:
                            self.console.print(f"è¯­éŸ³æ’­æ”¾é”™è¯¯: {e}", style="red")

                    current_response = []
                    self.running_step = 0 if not self.paused else 2
            except KeyError:
                pass

    async def run(self):
        """ä¸»è¿è¡Œå‡½æ•°"""
        proxy = Proxy.from_url(os.environ["HTTP_PROXY"]) if os.environ.get("HTTP_PROXY") else None
        if proxy:
            self.console.print("ä½¿ç”¨ä»£ç†", style="yellow")
        else:
            self.console.print("ä¸ä½¿ç”¨ä»£ç†", style="yellow")

        async with (proxy_connect(uri, proxy=proxy) if proxy else connect(uri)) as ws:
            self.ws = ws
            self.console.print("Gemini è‹±è¯­å£è¯­åŠ©æ‰‹", style="green", highlight=True)
            self.console.print("Make by twitter: @BoxMrChen", style="blue")
            self.console.print("============================================", style="yellow")
            
            await self.startup()

            async with asyncio.TaskGroup() as tg:
                tg.create_task(self.listen_audio())
                tg.create_task(self.send_audio())
                tg.create_task(self.receive_audio())

                def check_error(task):
                    if task.cancelled():
                        return
                    if task.exception():
                        print(f"Error: {task.exception()}")
                        sys.exit(1)

                for task in tg._tasks:
                    task.add_done_callback(check_error)

if __name__ == "__main__":
    main = AudioLoop()
    asyncio.run(main.run())